"""
å‚æ•°è‡ªåŠ¨ä¼˜åŒ–ç³»ç»Ÿ
æ”¯æŒç½‘æ ¼æœç´¢å’Œè´å¶æ–¯ä¼˜åŒ–
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Callable
import itertools
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥ç­–ç•¥å’Œæ¨¡å—
from strategies import get_strategy
from multi_strategy_evaluator import MultiStrategyEvaluator

try:
    import optuna
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    print("âš ï¸ Optunaæœªå®‰è£…ï¼Œå°†åªä½¿ç”¨ç½‘æ ¼æœç´¢ã€‚å®‰è£…å‘½ä»¤: pip install optuna")

class ParameterOptimizer:
    """å‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        self.evaluator = MultiStrategyEvaluator(config_path)
        self.optimization_results = {}
        
    def grid_search_optimization(self, 
                               strategy_name: str,
                               symbol: str,
                               param_ranges: Dict[str, List],
                               timeframe: str = '1h',
                               initial_capital: float = 10000,
                               objective: str = 'sharpe_ratio',
                               max_combinations: int = 1000,
                               parallel: bool = True) -> Dict:
        """
        ç½‘æ ¼æœç´¢å‚æ•°ä¼˜åŒ–
        
        Args:
            strategy_name: ç­–ç•¥åç§°
            symbol: äº¤æ˜“å¯¹
            param_ranges: å‚æ•°èŒƒå›´å­—å…¸
            timeframe: æ—¶é—´å‘¨æœŸ
            initial_capital: åˆå§‹èµ„é‡‘
            objective: ä¼˜åŒ–ç›®æ ‡ ('sharpe_ratio', 'total_return', 'profit_factor')
            max_combinations: æœ€å¤§ç»„åˆæ•°
            parallel: æ˜¯å¦å¹¶è¡Œæ‰§è¡Œ
            
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        print(f"ğŸ” å¼€å§‹ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        print(f"ç­–ç•¥: {strategy_name}")
        print(f"äº¤æ˜“å¯¹: {symbol}")
        print(f"ä¼˜åŒ–ç›®æ ‡: {objective}")
        print("=" * 60)
        
        # ç”Ÿæˆå‚æ•°ç»„åˆ
        param_combinations = self._generate_param_combinations(param_ranges, max_combinations)
        print(f"å‚æ•°ç»„åˆæ•°é‡: {len(param_combinations)}")
        
        if len(param_combinations) == 0:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å‚æ•°ç»„åˆ")
            return {}
        
        # æ‰§è¡Œä¼˜åŒ–
        start_time = time.time()
        
        if parallel and len(param_combinations) > 1:
            results = self._run_parallel_optimization(
                strategy_name, symbol, param_combinations, 
                timeframe, initial_capital, objective
            )
        else:
            results = self._run_sequential_optimization(
                strategy_name, symbol, param_combinations,
                timeframe, initial_capital, objective
            )
        
        end_time = time.time()
        
        # åˆ†æç»“æœ
        optimization_result = self._analyze_optimization_results(
            results, param_ranges, objective, end_time - start_time
        )
        
        # ä¿å­˜ç»“æœ
        key = f"{strategy_name}_{symbol.replace('/', '_')}_grid"
        self.optimization_results[key] = optimization_result
        
        return optimization_result
    
    def bayesian_optimization(self,
                            strategy_name: str,
                            symbol: str,
                            param_ranges: Dict[str, Tuple],
                            timeframe: str = '1h',
                            initial_capital: float = 10000,
                            objective: str = 'sharpe_ratio',
                            n_trials: int = 100,
                            timeout: int = 3600) -> Dict:
        """
        è´å¶æ–¯ä¼˜åŒ–å‚æ•°æœç´¢
        
        Args:
            strategy_name: ç­–ç•¥åç§°
            symbol: äº¤æ˜“å¯¹
            param_ranges: å‚æ•°èŒƒå›´å­—å…¸ {param: (min, max, step)}
            timeframe: æ—¶é—´å‘¨æœŸ
            initial_capital: åˆå§‹èµ„é‡‘
            objective: ä¼˜åŒ–ç›®æ ‡
            n_trials: è¯•éªŒæ¬¡æ•°
            timeout: è¶…æ—¶æ—¶é—´(ç§’)
            
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        if not OPTUNA_AVAILABLE:
            print("âŒ Optunaæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–")
            return {}
        
        print(f"ğŸ§  å¼€å§‹è´å¶æ–¯ä¼˜åŒ–")
        print(f"ç­–ç•¥: {strategy_name}")
        print(f"äº¤æ˜“å¯¹: {symbol}")
        print(f"ä¼˜åŒ–ç›®æ ‡: {objective}")
        print(f"è¯•éªŒæ¬¡æ•°: {n_trials}")
        print("=" * 60)
        
        # åˆ›å»ºä¼˜åŒ–ç›®æ ‡å‡½æ•°
        def objective_function(trial):
            # ç”Ÿæˆå‚æ•°
            params = {}
            for param_name, (min_val, max_val, step) in param_ranges.items():
                if isinstance(min_val, int) and isinstance(max_val, int):
                    params[param_name] = trial.suggest_int(param_name, min_val, max_val, step=step)
                else:
                    params[param_name] = trial.suggest_float(param_name, min_val, max_val, step=step)
            
            # æ‰§è¡Œå•æ¬¡å›æµ‹
            result = self._single_backtest_with_params(
                strategy_name, symbol, params, timeframe, initial_capital
            )
            
            if result is None:
                return -999  # å¤±è´¥æ—¶è¿”å›å¾ˆä½çš„åˆ†æ•°
            
            # è¿”å›ä¼˜åŒ–ç›®æ ‡å€¼
            return result.get(objective, 0)
        
        # åˆ›å»ºç ”ç©¶å¯¹è±¡
        study = optuna.create_study(
            direction='maximize',
            sampler=optuna.samplers.TPESampler(seed=42)
        )
        
        # æ‰§è¡Œä¼˜åŒ–
        start_time = time.time()
        study.optimize(objective_function, n_trials=n_trials, timeout=timeout)
        end_time = time.time()
        
        # åˆ†æç»“æœ
        optimization_result = self._analyze_bayesian_results(
            study, objective, end_time - start_time
        )
        
        # ä¿å­˜ç»“æœ
        key = f"{strategy_name}_{symbol.replace('/', '_')}_bayesian"
        self.optimization_results[key] = optimization_result
        
        return optimization_result
    
    def _generate_param_combinations(self, param_ranges: Dict[str, List], 
                                   max_combinations: int) -> List[Dict]:
        """ç”Ÿæˆå‚æ•°ç»„åˆ"""
        # è®¡ç®—æ€»ç»„åˆæ•°
        total_combinations = 1
        for values in param_ranges.values():
            total_combinations *= len(values)
        
        if total_combinations > max_combinations:
            print(f"âš ï¸ æ€»ç»„åˆæ•°({total_combinations})è¶…è¿‡é™åˆ¶({max_combinations})")
            print("å°†ä½¿ç”¨éšæœºé‡‡æ ·å‡å°‘ç»„åˆæ•°")
            
            # éšæœºé‡‡æ ·
            combinations = []
            np.random.seed(42)
            
            for _ in range(max_combinations):
                combination = {}
                for param_name, values in param_ranges.items():
                    combination[param_name] = np.random.choice(values)
                combinations.append(combination)
            
            return combinations
        else:
            # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
            param_names = list(param_ranges.keys())
            param_values = list(param_ranges.values())
            
            combinations = []
            for combination in itertools.product(*param_values):
                param_dict = dict(zip(param_names, combination))
                combinations.append(param_dict)
            
            return combinations
    
    def _run_parallel_optimization(self, strategy_name: str, symbol: str,
                                 param_combinations: List[Dict],
                                 timeframe: str, initial_capital: float,
                                 objective: str) -> List[Dict]:
        """å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–"""
        results = []
        
        with ThreadPoolExecutor(max_workers=4) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_params = {
                executor.submit(
                    self._single_backtest_with_params,
                    strategy_name, symbol, params, timeframe, initial_capital
                ): params
                for params in param_combinations
            }
            
            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(future_to_params):
                params = future_to_params[future]
                try:
                    result = future.result()
                    if result:
                        result['params'] = params
                        results.append(result)
                    
                    completed += 1
                    if completed % 10 == 0:
                        print(f"å·²å®Œæˆ: {completed}/{len(param_combinations)}")
                        
                except Exception as e:
                    print(f"âš ï¸ å‚æ•°ç»„åˆå¤±è´¥ {params}: {e}")
        
        return results
    
    def _run_sequential_optimization(self, strategy_name: str, symbol: str,
                                   param_combinations: List[Dict],
                                   timeframe: str, initial_capital: float,
                                   objective: str) -> List[Dict]:
        """ä¸²è¡Œæ‰§è¡Œä¼˜åŒ–"""
        results = []
        
        for i, params in enumerate(param_combinations, 1):
            print(f"[{i}/{len(param_combinations)}] æµ‹è¯•å‚æ•°: {params}")
            
            result = self._single_backtest_with_params(
                strategy_name, symbol, params, timeframe, initial_capital
            )
            
            if result:
                result['params'] = params
                results.append(result)
                print(f"âœ… {objective}: {result.get(objective, 0):.4f}")
            else:
                print("âŒ å›æµ‹å¤±è´¥")
        
        return results
    
    def _single_backtest_with_params(self, strategy_name: str, symbol: str,
                                   params: Dict, timeframe: str,
                                   initial_capital: float) -> Optional[Dict]:
        """ä½¿ç”¨æŒ‡å®šå‚æ•°æ‰§è¡Œå•æ¬¡å›æµ‹"""
        try:
            # è·å–æ•°æ®
            data = self.evaluator._get_backtest_data(symbol, timeframe, None, None)
            if data.empty:
                return None
            
            # åˆ›å»ºç­–ç•¥å®ä¾‹
            strategy = get_strategy(strategy_name, **params)
            
            # ç”Ÿæˆä¿¡å·
            signals = strategy.generate_signals(data)
            
            # æ‰§è¡Œå›æµ‹
            result = self.evaluator._execute_backtest(
                signals, strategy, symbol, initial_capital
            )
            
            return result
            
        except Exception as e:
            return None
    
    def _analyze_optimization_results(self, results: List[Dict], 
                                    param_ranges: Dict, objective: str,
                                    elapsed_time: float) -> Dict:
        """åˆ†æä¼˜åŒ–ç»“æœ"""
        if not results:
            return {'error': 'æ²¡æœ‰æœ‰æ•ˆçš„ä¼˜åŒ–ç»“æœ'}
        
        # æŒ‰ç›®æ ‡å€¼æ’åº
        results.sort(key=lambda x: x.get(objective, -999), reverse=True)
        
        best_result = results[0]
        worst_result = results[-1]
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        objective_values = [r.get(objective, 0) for r in results]
        
        analysis = {
            'optimization_type': 'grid_search',
            'objective': objective,
            'total_combinations': len(results),
            'elapsed_time': elapsed_time,
            'best_params': best_result['params'],
            'best_score': best_result.get(objective, 0),
            'best_result': best_result,
            'worst_score': worst_result.get(objective, 0),
            'mean_score': np.mean(objective_values),
            'std_score': np.std(objective_values),
            'all_results': results[:10],  # ä¿å­˜å‰10ä¸ªç»“æœ
            'param_sensitivity': self._analyze_param_sensitivity(results, objective)
        }
        
        # æ‰“å°ç»“æœ
        self._print_optimization_summary(analysis)
        
        return analysis
    
    def _analyze_bayesian_results(self, study, objective: str, 
                                elapsed_time: float) -> Dict:
        """åˆ†æè´å¶æ–¯ä¼˜åŒ–ç»“æœ"""
        best_trial = study.best_trial
        
        analysis = {
            'optimization_type': 'bayesian',
            'objective': objective,
            'total_trials': len(study.trials),
            'elapsed_time': elapsed_time,
            'best_params': best_trial.params,
            'best_score': best_trial.value,
            'best_trial': best_trial,
            'study': study
        }
        
        # æ‰“å°ç»“æœ
        self._print_optimization_summary(analysis)
        
        return analysis
    
    def _analyze_param_sensitivity(self, results: List[Dict], 
                                 objective: str) -> Dict:
        """åˆ†æå‚æ•°æ•æ„Ÿæ€§"""
        if len(results) < 10:
            return {}
        
        # åˆ›å»ºDataFrameä¾¿äºåˆ†æ
        data = []
        for result in results:
            row = result['params'].copy()
            row[objective] = result.get(objective, 0)
            data.append(row)
        
        df = pd.DataFrame(data)
        
        # è®¡ç®—ç›¸å…³æ€§
        correlations = {}
        for param in df.columns:
            if param != objective:
                try:
                    corr = df[param].corr(df[objective])
                    if not pd.isna(corr):
                        correlations[param] = corr
                except:
                    pass
        
        return correlations
    
    def _print_optimization_summary(self, analysis: Dict):
        """æ‰“å°ä¼˜åŒ–ç»“æœæ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ¯ å‚æ•°ä¼˜åŒ–ç»“æœæ‘˜è¦")
        print("="*60)
        
        print(f"ä¼˜åŒ–ç±»å‹: {analysis['optimization_type']}")
        print(f"ä¼˜åŒ–ç›®æ ‡: {analysis['objective']}")
        print(f"æ€»è¯•éªŒæ¬¡æ•°: {analysis.get('total_combinations', analysis.get('total_trials', 0))}")
        print(f"è€—æ—¶: {analysis['elapsed_time']:.2f}ç§’")
        
        print(f"\nğŸ† æœ€ä½³ç»“æœ:")
        print(f"æœ€ä½³å‚æ•°: {analysis['best_params']}")
        print(f"æœ€ä½³å¾—åˆ†: {analysis['best_score']:.4f}")
        
        if 'mean_score' in analysis:
            print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"å¹³å‡å¾—åˆ†: {analysis['mean_score']:.4f}")
            print(f"æ ‡å‡†å·®: {analysis['std_score']:.4f}")
            print(f"æœ€å·®å¾—åˆ†: {analysis['worst_score']:.4f}")
        
        if 'param_sensitivity' in analysis and analysis['param_sensitivity']:
            print(f"\nğŸ” å‚æ•°æ•æ„Ÿæ€§åˆ†æ:")
            for param, corr in sorted(analysis['param_sensitivity'].items(), 
                                    key=lambda x: abs(x[1]), reverse=True):
                print(f"{param}: {corr:.3f}")
        
        print("="*60)
    
    def compare_optimization_methods(self, strategy_name: str, symbol: str,
                                   param_ranges_grid: Dict[str, List],
                                   param_ranges_bayesian: Dict[str, Tuple],
                                   objective: str = 'sharpe_ratio') -> Dict:
        """æ¯”è¾ƒä¸åŒä¼˜åŒ–æ–¹æ³•"""
        print("ğŸ”¬ æ¯”è¾ƒä¼˜åŒ–æ–¹æ³•æ€§èƒ½")
        print("="*60)
        
        results = {}
        
        # ç½‘æ ¼æœç´¢
        print("1. æ‰§è¡Œç½‘æ ¼æœç´¢...")
        grid_result = self.grid_search_optimization(
            strategy_name, symbol, param_ranges_grid, 
            objective=objective, max_combinations=100
        )
        results['grid_search'] = grid_result
        
        # è´å¶æ–¯ä¼˜åŒ–
        if OPTUNA_AVAILABLE:
            print("\n2. æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–...")
            bayesian_result = self.bayesian_optimization(
                strategy_name, symbol, param_ranges_bayesian,
                objective=objective, n_trials=100
            )
            results['bayesian'] = bayesian_result
        
        # æ¯”è¾ƒç»“æœ
        print("\n" + "="*60)
        print("ğŸ“ˆ ä¼˜åŒ–æ–¹æ³•å¯¹æ¯”")
        print("="*60)
        
        for method, result in results.items():
            if result and 'best_score' in result:
                print(f"{method}:")
                print(f"  æœ€ä½³å¾—åˆ†: {result['best_score']:.4f}")
                print(f"  æœ€ä½³å‚æ•°: {result['best_params']}")
                print(f"  è€—æ—¶: {result['elapsed_time']:.2f}ç§’")
                print()
        
        return results
    
    def save_optimization_results(self, filepath: str):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        import json
        
        # å‡†å¤‡å¯åºåˆ—åŒ–çš„æ•°æ®
        serializable_results = {}
        for key, result in self.optimization_results.items():
            serializable_result = {}
            for k, v in result.items():
                if k not in ['study', 'best_trial', 'all_results']:  # è·³è¿‡ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
                    try:
                        json.dumps(v)  # æµ‹è¯•æ˜¯å¦å¯åºåˆ—åŒ–
                        serializable_result[k] = v
                    except:
                        serializable_result[k] = str(v)
            
            serializable_results[key] = serializable_result
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ä¼˜åŒ–ç»“æœå·²ä¿å­˜åˆ°: {filepath}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ParameterOptimizer()
    
    # å®šä¹‰å‚æ•°èŒƒå›´
    param_ranges_grid = {
        'fast_ma': [10, 15, 20, 25],
        'slow_ma': [30, 40, 50, 60],
        'rsi_period': [12, 14, 16],
        'rsi_overbought': [70, 75, 80]
    }
    
    param_ranges_bayesian = {
        'fast_ma': (5, 30, 1),
        'slow_ma': (20, 100, 5),
        'rsi_period': (10, 20, 1),
        'rsi_overbought': (65, 85, 1)
    }
    
    # æ‰§è¡Œä¼˜åŒ–
    result = optimizer.grid_search_optimization(
        strategy_name='trend_ma_breakout',
        symbol='BTC/USDT',
        param_ranges=param_ranges_grid,
        objective='sharpe_ratio',
        max_combinations=50
    )
    
    # ä¿å­˜ç»“æœ
    optimizer.save_optimization_results('results/optimization_results.json')
